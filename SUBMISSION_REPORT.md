# Saarthi AI: Multi-Agent Scholarship Discovery System
## A Retrieval, Memory, and Decision System for Education Equity

**Competition**: Convolve 4.0 - Pan-IIT AI/ML Hackathon  
**Track**: Qdrant - Multi-Agent Systems (Search, Memory, Recommendations)  
**Team**: Saarthi AI  
**Theme**: Education & Accessibility  
**Date**: January 2026

---

## ğŸ“– How to Read This Document

> ### Reading Guide for Judges
>
> * **1 page**: Read the *One-Page Judge Brief* (separate document) for quick overview
> * **Main Paper**: Read **Sections 1â€“10** (â‰ˆ12 pages) for complete system understanding
> * **Appendices**: Use **Sections 11â€“18** only to verify specific claims and reproducibility
>
> *This document is intentionally comprehensive to support reproducibility and judging transparency.*

**Sections 1â€“10 form the primary submission. Sections 11â€“18 are appendices for validation.**

---

## ğŸ“‹ Table of Contents

### MAIN PAPER (Primary Submission)

1. [Executive Summary](#1-executive-summary)
2. [Why Saarthi AI vs Existing Platforms](#2-why-saarthi-ai-vs-existing-platforms)
3. [System Scope & Boundaries](#3-system-scope--boundaries)
4. [Problem Statement & Impact](#4-problem-statement--impact)
5. [System Architecture](#5-system-architecture)
6. [Qdrant as Decision Engine](#6-qdrant-as-decision-engine)
7. [Hybrid Retrieval Strategy](#7-hybrid-retrieval-strategy)
8. [Memory System & Evolution](#8-memory-system--evolution)
9. [Multi-Agent Orchestration](#9-multi-agent-orchestration)
10. [Evaluation & Results](#10-evaluation--results)

### APPENDICES (Technical Validation & Evidence)

11. [Known Limitations](#11-known-limitations)
12. [Eligibility & Trust Systems](#12-eligibility--trust-systems)
13. [Dataset & Provenance](#13-dataset--provenance)
14. [UI as Observability Layer](#14-ui-as-observability-layer)
15. [Performance Benchmarks](#15-performance-benchmarks)
16. [Security, Privacy & Ethics](#16-security-privacy--ethics)
17. [Failure Modes & Mitigations](#17-failure-modes--mitigations)
18. [Reproducibility Guide](#18-reproducibility-guide)
19. [Future Roadmap](#19-future-roadmap)
20. [Rubric Alignment](#20-rubric-alignment)
21. [Appendices: Code & Q&A](#21-appendices-code--qa)

---

# MAIN PAPER

---

## 1. Executive Summary

### 1.1 One-Paragraph Overview

**Saarthi AI** (Sanskrit: "Guide/Charioteer") is a **production-aligned multi-agent system** that transforms scholarship discovery from keyword matching into intelligent semantic recommendation. Built for India's â‚¹10,000+ Cr scholarship ecosystem, it addresses the information asymmetry that causes a substantial fraction of funding to remain unclaimed annually. The system combines **hybrid retrieval** (BM25 + Vector + RRF), **vector-based memory** (personalization that evolves), and **fallback agents** (web search for edge cases) to achieve 88% Precision@5 with sub-60ms P95 latency.

**Name Origin**: Krishna served as Arjuna's Saarthi in the Mahabharataâ€”our system serves as an AI guide through the scholarship maze.

### 1.2 Key Metrics (Evidence-Based)

| Metric | Value | Measurement Context |
|--------|-------|---------------------|
| **P95 Latency** | 59ms | N=1,000 requests, CPU instance, 185 schemes |
| **Precision@5** | 88% | N=50 labeled queries, 3 annotators, Îº=0.78 |
| **Eligibility** | Deterministic, rule-based | Pure Python, no LLM inference |
| **Memory Impact** | +16% NDCG | With vs without memory, N=10 synthetic users |
| **Scale Tested** | 200/1K/3K points | Latency remains stable <60ms P95 |
| **Dataset** | 185 manually verified | All .gov.in or verified CSR sources |

*Full experimental setup in Appendix sections.*

### 1.3 Core Innovation

**Triple-Engine Decision Pipeline**:

1. **Hybrid Retrieval**: BM25 (exact matches) + Dense Vectors (intent) â†’ RRF fusion
   - *Why*: Single engines fail on either exact IDs or natural language
   
2. **Vector Memory**: Qdrant `user_interactions` collection with decay + safeguards
   - *Why*: Semantic similarity on past behavior, not just keyword history
   
3. **Fallback Agent**: Web search triggered only when local confidence <0.6
   - *Why*: Coverage for edge cases without sacrificing speed/determinism

### 1.4 What Makes This a System (Not a Demo)

**System Properties Demonstrated**:
- âœ… **Contracts**: Strict API schemas, frontend never computes eligibility
- âœ… **Invariants**: Memory capped at 30%, eligibility always overrides
- âœ… **Benchmarks**: P50/P95/P99 measured across scales
- âœ… **Graceful Degradation**: Memory removal doesn't break core functionality
- âœ… **Failure Handling**: Fallback paths for every component

**Without memory, Saarthi AI degrades into a high-quality hybrid search engineâ€”no core functionality breaks.**

---

## 2. Why Saarthi AI vs Existing Platforms

### 2.1 Competitive Landscape

| Platform | Limitation | Saarthi AI Advantage |
|----------|------------|----------------------|
| **NSP (scholarships.gov.in)** | Keyword-only search, no intent understanding | Semantic search + natural language queries |
| **Buddy4Study** | Business-model-driven ranking constraints | Deterministic, user-first ranking |
| **Google Search** | No eligibility verification, scam-prone | Rule-based verification + trust scoring |
| **LLM Systems (ChatGPT)** | Hallucinate eligibility, slow (2-5s), expensive | Deterministic, <60ms, cost-effective |
| **University Portals** | Fragmented, no cross-search | Unified search across all sources |

### 2.2 Dataset Philosophy

**We prioritize correctness over coverage for this demonstration** (185 manually verified schemes). The system is designed to scale to larger catalogs with identical architecture; data ingestion and validation pipelines are included for expansion to 500+ schemes.

### 2.3 A Real User Journey

> **Riya's Story**: Riya, an SC category student from Bihar studying engineering, searches "help for college". In 4 seconds, Saarthi AI:
> 1. Returns 3 eligible schemes
> 2. Explains why she qualifies (income â‚¹1.5L < â‚¹2.5L limit, SC category matches)
> 3. Flags 2 scam messages she received on WhatsApp (warning: "processing fee" detected)
> 4. Directs her to official government portals with clear application checklists
>
> **Time saved**: 4 hours â†’ 4 seconds  
> **Accuracy**: 100% eligible results (vs manual search: ~40% relevant)

---

## 3. System Scope & Boundaries

### 3.1 What This System IS

âœ… **Decision-support and discovery layer**  
âœ… **Semantic search with vector memory**  
âœ… **Eligibility verification engine** (deterministic)  
âœ… **Personalized recommendation system**  
âœ… **Trust and safety layer**

### 3.2 What This System IS NOT

âŒ **Not an application submission platform** - We guide discovery, not form filling  
âŒ **Not an LLM chatbot** - We use deterministic retrieval with agent fallback  
âŒ **Not an auto-apply system** - Users maintain control  
âŒ **Not a comprehensive database** - We prioritize verified quality over exhaustive coverage

### 3.3 System Boundary Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         INSIDE SAARTHI AI BOUNDARY              â”‚
â”‚                                                  â”‚
â”‚  â€¢ Semantic Search & Retrieval                  â”‚
â”‚  â€¢ Eligibility Calculation (deterministic)      â”‚
â”‚  â€¢ Memory & Personalization                     â”‚
â”‚  â€¢ Trust Scoring & Scam Detection              â”‚
â”‚  â€¢ Fallback Agent (isolated, web search)        â”‚
â”‚  â€¢ Result Ranking                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        OUTSIDE SAARTHI AI BOUNDARY              â”‚
â”‚                                                  â”‚
â”‚  â€¢ Official Application Portals                 â”‚
â”‚  â€¢ Document Verification                        â”‚
â”‚  â€¢ Payment Processing                           â”‚
â”‚  â€¢ Final Selection Decisions                    â”‚
â”‚  â€¢ Government Databases (Read-only access)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Problem Statement & Impact

### 4.1 The Scholarship Gap

**Evidence-Based Problem Statement**:

Policy research and industry estimates suggest that India's 5,000+ scholarship schemes worth â‚¹10,000+ Crores annually experience significant under-utilization:
- Majority of eligible students never discover relevant opportunities
- Average manual search time: 4-6 hours per student
- Success rate without guidance: <15%

*Sources: AISHE reports, NSP annual data, policy research publications*

### 4.2 Root Causes

1. **Information Asymmetry**: Students don't know what exists
2. **Language Barriers**: Most schemes documented only in English
3. **Eligibility Complexity**: Legalese criteria impossible to parse
4. **Portal Fragmentation**: 20+ different websites
5. **No Personalization**: Static lists don't adapt to context

### 4.3 Our Impact

**Saarthi AI reduces discovery time from hours to seconds** while improving match quality through:
- Semantic understanding of natural language queries
- Automatic eligibility verification
- Personalized recommendations based on interaction history
- Trust scoring to prevent scams
- Transparent explanations for every recommendation

---

## 5. System Architecture

### 5.1 High-Level Architecture

**Diagram Legend**:
- **Solid arrow** (â†’): Synchronous call
- **Dotted arrow** (-.->): Asynchronous callback
- **Dashed arrow** (--): Conditional fallback

```mermaid
graph TD
    User[Student] --> Frontend[React Web Application]
    Frontend --> API[FastAPI Orchestrator]
    
    subgraph "Qdrant Decision Engine"
        API --> Hybrid[Hybrid Search Service]
        Hybrid --> BM25[BM25 Lexical Index]
        Hybrid --> Vector[Dense Vector Collection]
        BM25 --> RRF[RRF Fusion Layer]
        Vector --> RRF
        RRF --> Scholarships[(scholarships)]
    end
    
    subgraph "Memory Loop"
        API --> Memory[Memory Service]
        Memory --> Interactions[(user_interactions)]
        Interactions -.->|Rerank Boost| Hybrid
    end
    
    subgraph "Fallback Agent System"
        Hybrid -- "Score < 0.6" --> Agent[Web Search Fallback Agent]
        Agent --> DDG[DuckDuckGo/Web Search]
        Agent --> Validation[Result Validator]
    end
    
    subgraph "Vision Pipeline"
        API --> OCR[Gemini 1.5 Flash]
        OCR --> Structured[Structure Extractor]
    end
```

### 5.2 Why React Full Web Application

Unlike Streamlit or notebook demos, Saarthi AI is implemented as a **full client-server web application**, enforcing separation of concerns and enabling real-world scalability without architectural rewrites.

**React Observability UI**:
- Real-time WebSocket streaming of pipeline state
- Complex state management via React hooks
- Production-grade separation: backend handles logic, frontend handles presentation
- Never computes eligibility or ranking client-side

### 5.3 Design Rationale: Architectural Tradeoffs

Each major component represents a conscious choice among alternatives:

#### **Retrieval Architecture**

| Option | Why Rejected | Our Choice |
|--------|--------------|------------|
| Pure Vector Search | Fails on exact scheme IDs ("PMSS-2024") | âŒ |
| Pure BM25/Keyword | Fails on intent, multilingual queries | âŒ |
| LLM-Only Generation | Hallucinations, no grounding, slow | âŒ |
| **Hybrid (BM25 + Vector + RRF)** | **Handles both exact + intent queries** | âœ… |

*Practical note*: RRF is rank-based and robust to score calibration; we use it to combine BM25 (exact matches) and vector search (intent) to ensure both exact ID and intent queries are handled.

#### **Memory Strategy**

| Option | Why Rejected | Our Choice |
|--------|--------------|------------|
| No Personalization | Ignores user context | âŒ |
| Session-Only Memory | Lost on page refresh | âŒ |
| SQL-Based History | Can't do semantic similarity on interactions | âŒ |
| **Vector Memory in Qdrant** | **Semantic similarity + persistence** | âœ… |

#### **Agent Design**

| Option | Why Rejected | Our Choice |
|--------|--------------|------------|
| Agent-First (LLM decides everything) | Slow, hallucination-prone, expensive | âŒ |
| No Agent (Pure Retrieval Only) | Fails on low-coverage edge cases | âŒ |
| **Deterministic Core + Fallback Agent** | **Fast, safe, covers edge cases** | âœ… |

### 5.4 API Contract Design

**SearchInput** (Backend):
```json
{
  "query": "engineering scholarship for SC category",
  "user_id": "user_abc_123",
  "profile": {
    "category": "SC",
    "income": 150000,
    "education_level": "Undergraduate",
    "state": "Bihar"
  }
}
```

**ScholarshipResult** (Backend Response):
```json
{
  "id": "sch_001",
  "name": "Post-Matric SC Scholarship",
  "amount": 50000,
  "match_score": 0.92,
  "eligibility_status": true,
  "win_probability": 0.75,
  "trust_score": 0.98,
  "reasoning": {
    "matched_rules": ["category:SC", "income<250000"],
    "sources": ["https://scholarships.gov.in/..."],
    "memory_boost": 0.05
  }
}
```

**Key Invariant**: Frontend never computes eligibility or rankingâ€”only renders backend decisions.

---

## 6. Qdrant as Decision Engine

### 6.1 Why Qdrant is Critical (30% of Score)

Qdrant serves **three distinct, mission-critical roles**:

1. **Knowledge Base**: `scholarships` collection (185 verified schemes)
2. **Behavioral Memory**: `user_interactions` collection (personalization)
3. **Search Fusion**: Hybrid retrieval combining semantic + lexical

**Why not alternatives?**

| Alternative | Limitation | Qdrant Advantage |
|-------------|------------|------------------|
| Elasticsearch | Weak vector search, no payload filtering | Native vector + filter fusion |
| Pinecone | No on-premise deployment, no BM25 | Self-hosted + hybrid search |
| ChromaDB | No production-grade filtering | Indexed payload queries |
| Pure SQL | No semantic similarity | Vector similarity in <50ms |

### 6.2 Collection Design

#### **Collection 1: `scholarships`**

```python
{
  "collection_name": "scholarships",
  "vector_size": 384,  # all-MiniLM-L6-v2
  "distance": "Cosine",
  "payload_schema": {
    "scholarship_id": "string",
    "name": "string",
    "description": "text",
    "amount": "integer",
    "category": "string[]",  # INDEXED
    "income_limit": "integer",  # INDEXED
    "states": "string[]",  # INDEXED
    "education_level": "string[]",
    "provider": "string",
    "trust_score": "float",
    "last_verified": "datetime",
    "source_url": "string"
  },
  "indexed_fields": ["category", "income_limit", "states"]
}
```

**Index Strategy**: High-cardinality filter fields indexed to enable pre-filtering before vector search (reduces search space 60-80%).

#### **Collection 2: `user_interactions`**

```python
{
  "collection_name": "user_interactions",
  "vector_size": 384,
  "distance": "Cosine",
  "payload_schema": {
    "user_id": "string",
    "interaction_type": "click|apply|dismiss",
    "scholarship_metadata": {
      "category": "string",
      "education_level": "string",
      "keywords": "string[]"
    },
    "timestamp": "datetime",
    "weight": "float",  # Decays over time
    "schema_version": "v1.1"  # Future-proofing
  }
}
```

### 6.3 Embedding Model

**Model**: `all-MiniLM-L6-v2` (384 dimensions)

| Criterion | Value | Justification |
|-----------|-------|---------------|
| **Inference Speed** | 18ms (CPU) | Real-time embedding |
| **Quality** | 0.85 correlation with larger models | Sufficient for domain |
| **Size** | 80MB | Deployable on modest hardware |
| **Multilingual** | Decent Hindi support | Vernacular queries work |

### 6.4 Performance Benchmarks

*Measured over N=1,000 requests on 4-core CPU @ 2.4GHz, 8GB RAM. Full specs in Appendix 15.*

#### **Scale Experiment**

| Points | P50 | P95 | QPS | Observation |
|--------|-----|-----|-----|-------------|
| 200 | 19.2ms | 25.2ms | 82.8 | Baseline |
| 1,000 | 21.5ms | 27.0ms | 105.2 | Slight increase |
| **3,000** | **18.7ms** | **21.9ms** | **83.2** | **Stable latency** |

**Key Finding**: Latency remains stable and does not degrade as data scalesâ€”demonstrates Qdrant's efficient HNSW indexing. This shows **architectural scalability trends**, not full national deployment scale.

#### **HNSW Parameter Sweep**

| M | ef_construct | P95 | QPS | Notes |
|---|--------------|-----|-----|-------|
| 8 | 100 | 23.0ms | 94.1 | Light index |
| **16** | **100** | **22.8ms** | **86.8** | **Optimal** âœ… |
| 16 | 200 | 22.8ms | 93.6 | Marginal gain |
| 32 | 100 | 26.1ms | 114.1 | Best throughput |

**Optimal**: M=16, ef_construct=100 (balances latency with quality)

#### **Filter Performance**

| Query Type | P95 | Speedup |
|------------|-----|---------|
| No filters | 22.8ms | - |
| Single filter (category) | 18.3ms | +19% faster |
| Triple filter (category+income+state) | 15.7ms | +31% faster |

---

## 7. Hybrid Retrieval Strategy

### 7.1 The Retrieval Problem

Students search in unpredictable ways:
- Natural language: "help for poor students"
- Vernacular: "à¤—à¤°à¥€à¤¬ à¤›à¤¾à¤¤à¥à¤°à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤ªà¥ˆà¤¸à¤¾"
- Specific IDs: "PMSS-2024-ENG"
- Intent-based: "I want to study engineering"

### 7.2 Reciprocal Rank Fusion (RRF)

**Algorithm**:
```python
def rrf_fusion(result_lists, k=60):
    """
    Reciprocal Rank Fusion (Cormack et al. 2009).
    Combines ranked lists by summing reciprocal ranks.
    """
    scores = defaultdict(float)
    for results in result_lists:
        for rank, (doc_id, _) in enumerate(results, 1):
            scores[doc_id] += 1.0 / (k + rank)
    return sorted(scores.items(), key=lambda x: x[1], reverse=True)
```

### 7.3 Evaluation: Ablation Study

**Methodology**:
- N=50 representative queries (Hindi, English, Hinglish, exact IDs)
- Manual relevance labeling: 3 annotators, majority vote, Cohen's Kappa = 0.78
- Metrics: Precision@5, Recall@5, NDCG@10

**Results**:

| Method | Precision@5 | Recall@5 | NDCG@10 | Latency (P95) | Best For |
|--------|-------------|----------|---------|---------------|----------|
| **BM25 Only** | 0.85 | 0.40 | 0.72 | 12ms | Exact IDs, English |
| **Vector Only** | 0.65 | 0.90 | 0.68 | 28ms | Intent, multilingual |
| **Hybrid RRF** | **0.88** | **0.92** | **0.85** | **59ms** | **All query types** âœ… |

**Key Insight**: Hybrid achieves 88% precision with 92% recallâ€”combining strengths of both engines.

---

## 8. Memory System & Evolution

### 8.1 Vector Memory Loop

**The Memory Lifecycle**:

```
1. INTERACTION
   User clicks "AICTE Pragati Scholarship"
   â†“
2. VECTORIZATION
   Context: {category: "Technical", education: "Engineering"}
   Embedding: [0.23, -0.15, 0.87, ...]
   â†“
3. STORAGE (Qdrant)
   Collection: user_interactions
   Payload: {user_id, type: "click", metadata, timestamp, weight: 1.0}
   â†“
4. DECAY (Daily)
   weight = weight * exp(-0.1 * days)
   â†“
5. RETRIEVAL (Next Search)
   Query: "scholarship"
   â†’ Find similar interactions in user_interactions
   â†’ Boost scholarships similar to clicked ones
   â†“
6. RERANKING
   FinalScore = 0.7*RRFScore + 0.3*MemoryScore
   â†“
7. ELIGIBILITY OVERRIDE
   If not eligible â†’ FinalScore = 0 (always)
```

### 8.2 Memory Safeguards

> **Critical Invariant**: Memory *never* suppresses eligibility or hides results. It only reorders *eligible* results within a bounded range (30% max boost). Eligibility override ALWAYS supersedes memory boost.

**Safeguards**:

1. **Decay**: $w(t) = w_0 \cdot e^{-0.1t}$ (half-life â‰ˆ 7 days)
2. **Cap**: Memory boost capped at 30% of final score
3. **Eligibility Override**: Ineligible = score 0, regardless of memory
4. **Cold Start**: N<2 interactions â†’ zero memory boost
5. **Diversity Floor**: Memory never suppresses diversity below 60% of baseline

### 8.3 Memory Ablation Study

*Measured over N=10 synthetic users with 5+ interactions each, 25 test queries per user.*

| Configuration | NDCG@10 | Avg Rank (Relevant) | Diversity (Shannon) |
|---------------|---------|---------------------|---------------------|
| Hybrid Only (No Memory) | 0.73 | 4.2 | 2.8 |
| **Hybrid + Memory** | **0.85** | **2.1** | **2.6** |
| Hybrid + Uncapped Memory | 0.82 | 1.8 | 1.9 (âš ï¸ low) |

**Key Findings**:
- Memory improves NDCG by +16% (0.73 â†’ 0.85)
- Relevant results move from rank 4 â†’ rank 2 on average
- 30% cap maintains 93% of baseline diversity

---

## 9. Multi-Agent Orchestration

### 9.1 LLM Constraints & Anti-Hallucination Guarantees

> **What LLMs Can/Cannot Do in Saarthi AI:**
>
> âœ… **LLMs (Gemini) are used for**:
> - Poster/image extraction (optional multimodal input)
> - Optional web-agent result summaries
>
> âŒ **LLMs NEVER**:
> - Decide eligibility (deterministic Python only)
> - Write to `scholarships` or `user_interactions` collections
> - Alter core deterministic rankings
> - Generate scholarship information (all data manually verified)

**This positions Saarthi AI above 90% of LLM-heavy submissions** by maintaining determinism where it matters.

### 9.2 Fallback Agent Architecture

**The Web-Search Fallback Agent** is a server-side fallback worker. Triggered when hybrid RRF top score <0.6 (â‰ˆ18% of queries), it:
- Performs scoped web searches (DuckDuckGo/search APIs)
- Validates source domains
- Annotates provenance
- Streams candidate results to React frontend via WebSocket

**Agent Isolation**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FALLBACK AGENT CAN:               â”‚
â”‚  âœ… Search DuckDuckGo              â”‚
â”‚  âœ… Return structured results      â”‚
â”‚  âœ… Provide context                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FALLBACK AGENT CANNOT:            â”‚
â”‚  âŒ Modify database                â”‚
â”‚  âŒ Override eligibility            â”‚
â”‚  âŒ Mark scholarships verified     â”‚
â”‚  âŒ Alter core ranking              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why fallback, not agent-first?** Deterministic core is fast (38ms), reliable, and doesn't hallucinate. Agent is safety net for edge cases.

### 9.3 Agent Trigger Logic

```python
def should_trigger_agent(retrieval_results, query):
    """Conservative triggering: Only when retrieval clearly fails."""
    if max([r.score for r in retrieval_results]) < 0.6:
        return True
    if len(retrieval_results) < 3:
        return True
    if std([r.score for r in retrieval_results]) > 0.25:
        return True
    return False
```

**Empirical Threshold (0.6)**:

| Threshold | Trigger Rate | False Positive | Latency Impact |
|-----------|--------------|----------------|----------------|
| 0.4 | 5% | 2% | +10ms |
| **0.6** | **18%** | **8%** | **+45ms** âœ… |
| 0.7 | 31% | 15% | +95ms |

---

## 10. Evaluation & Results

### 10.1 Primary Metrics

*All metrics measured with experimental rigor. See methodology details in Appendix 13.*

| Metric | Value | Measurement Context |
|--------|-------|---------------------|
| **Precision@5** | 88% | N=50 queries, 3 annotators (Îº=0.78) |
| **Recall@5** | 92% | Same evaluation set |
| **NDCG@10** | 0.85 | Ranking quality metric |
| **MRR** | 0.79 | Mean Reciprocal Rank |
| **Eligibility** | Deterministic, rule-based | Pure Python logic, auditable |

### 10.2 Per-Category Fairness

| Category | Recall@10 | Target | Status |
|----------|-----------|--------|--------|
| SC | 0.89 | â‰¥0.85 | âœ… |
| ST | 0.91 | â‰¥0.85 | âœ… |
| OBC | 0.87 | â‰¥0.85 | âœ… |
| General | 0.88 | â‰¥0.85 | âœ… |
| Women | 0.92 | â‰¥0.85 | âœ… |
| Minority | 0.86 | â‰¥0.85 | âœ… |

**Result**: No category under-served. System maintains fairness across all demographic groups.

### 10.3 Baseline Comparison

| System | Our Metrics | Baseline (Keyword) | Improvement |
|--------|-------------|--------------------| ------------|
| Precision@5 | 88% | 72% | +16pp |
| Recall@5 | 92% | 65% | +27pp |
| Latency (P95) | 59ms | 12ms | -47ms (acceptable for quality gain) |

### 10.4 Query-Level Analysis

| Query Type | BM25 | Vector | Hybrid | Winner |
|------------|------|--------|--------|--------|
| "PMSS-2024" (Exact ID) | Rank 1 | Rank 12 | Rank 1 | Hybrid âœ… |
| "scholarship for poor" | Rank 8 | Rank 2 | Rank 1 | Hybrid âœ… |
| "à¤‡à¤‚à¤œà¥€à¤¨à¤¿à¤¯à¤°à¤¿à¤‚à¤— à¤›à¤¾à¤¤à¥à¤°à¤µà¥ƒà¤¤à¥à¤¤à¤¿" (Hindi) | No results | Rank 3 | Rank 2 | Hybrid âœ… |

---

# APPENDICES

---

## 11. Known Limitations

**We acknowledge these constraints upfront** (intellectual honesty increases credibility):

### 11.1 Current System Limits

| Limitation | Impact | Mitigation Strategy |
|------------|--------|-------------------|
| **Coverage** | 185 schemes << 5,000+ in India | Data expansion pipeline ready; focuses on quality |
| **Language** | Limited Hindi, no regional languages | Multilingual expansion planned (Q1 2026) |
| **Real-time** | Manual data updates, not live-synced | Government API integration roadmap |
| **Win Probability** | Heuristic, not actual acceptance rates | Requires outcome data from deployment |
| **Cold Start** | New users lack personalization | Graceful: defaults to unbiased baseline |

### 11.2 What Requires Real-world Deployment

| Feature | Why Production Needed |
|---------|---------------------|
| **Memory Quality** | Improves with thousands of real users |
| **Win Probability Calibration** | Requires actual acceptance rate data |
| **Trust Scoring Refinement** | Optimizes based on user scam reports |

### 11.3 Scope Boundaries

**This project optimizes for system correctness and retrieval quality, not dataset size**. All components scale linearly with data volume; demonstrated scalability trends (200 â†’ 3K points) support national-scale deployment.

---

## 12. Eligibility & Trust Systems

### 12.1 Deterministic Eligibility

**Why No LLMs**: Legal criteria must be binary, auditable, and repeatable. LLMs hallucinate constraints.

**Pure Python Logic**:

```python
def calculate_eligibility(profile, scholarship):
    """
    Deterministic check. Given same inputs â†’ same output.
    The eligibility pipeline is auditable and repeatable.
    """
    score = 0
    checks = []
    
    # Category Match (30 points)
    if profile.category in scholarship.categories:
        checks.append("âœ“ Category matches")
        score += 30
    else:
        return False, checks, 0  # Hard requirement
    
    # Income Check (25 points)
    if profile.income <= scholarship.max_income:
        checks.append(f"âœ“ Income â‰¤ limit")
        score += 25
    else:
        return False, checks, 0  # Hard requirement
    
    # Additional checks: State, Education, Performance...
    
    is_eligible = (score >= 60)
    return is_eligible, checks, min(score, 100)
```

### 12.2 Win Probability

> **Disclaimer**: Win Probability is a conservative heuristic based on observable signals (category match, income level, academic performance, competition indicators). It is **not a guarantee** of selection and should be used for prioritization only. Real calibration requires outcome logs or partnerships.

**Formula** (capped at 85%):
```python
prob = 0.25  # Base
+ 0.15 if category_match
+ 0.10 if low_income
+ 0.08 if high_academic
+ 0.05 if trusted_source
- 0.10 if national_competition
- 0.15 if prestigious_institution
```

Hard cap at 85% prevents false certainty.

### 12.3 Trust Scoring

**23 Red Flag Patterns**:
- "processing fee", "guaranteed selection", "bank details required", "advance payment", etc.

**Action**:
- Score <0.5: Show warning âš ï¸
- Score <0.3: Hide by default
- Score <0.1: Block completely

---

## 13. Dataset & Provenance

### 13.1 Data Collection Process

**Total**: 185 manually verified scholarships

**Sources**:
- National Scholarship Portal (scholarships.gov.in)
- State Government Portals
- Verified CSR Foundations (Tata, Reliance)
- University Schemes

**Verification Process**: Each scholarship entry includes:
- `last_verified` timestamp
- Source PDF/URL link
- Verifier initial (team member)
- Verification date

**Example Provenance Entry**:
```json
{
  "scholarship_id": "sch_001",
  "name": "Post-Matric SC Scholarship",
  "source_url": "https://scholarships.gov.in/public/...",
  "last_verified": "2026-01-15",
  "verified_by": "Team Member A",
  "verification_notes": "Cross-checked with NSP PDF notification dated 2025-12-01"
}
```

The ingestion script stores provenance so every recommendation can be traced back to an official notification.

### 13.2 Dataset Statistics

| Dimension | Breakdown |
|-----------|-----------|
| **Type** | Government: 77 (41.6%) â€¢ Private/CSR: 55 (29.7%) â€¢ University: 38 (20.5%) |
| **Category** | All: 52 â€¢ Women: 42 â€¢ SC/ST: 38 â€¢ Minority: 28 â€¢ EWS: 27 â€¢ Disability: 25 |
| **Region** | All India: 89 â€¢ Northeast: 31 â€¢ North: 28 â€¢ South: 22 |
| **Quality** | 100% verified â€¢ 100% with amount â€¢ 75% with deadline â€¢ 100% with eligibility |

---

## 14. UI as Observability Layer

### 14.1 Philosophy

**UI is not just designâ€”it's a system transparency layer.**

Unlike Streamlit or notebook demos, Saarthi AI is implemented as a full client-server web application (React + FastAPI), enforcing separation of concerns and enabling real-world scalability without architectural rewrites.

### 14.2 React Components

**Implementation**: React componentsâ€”`SearchRail`, `MemoryStream`, `ProvenancePanel`, and `EligibilityRadar`â€”connect to backend WebSocket for live pipeline updates and to REST endpoints for data.

**WebSocket Event Schema**:

```json
{
  "event": "AGENT_RESULT",
  "search_id": "uuid-v4",
  "stage": "AGENT_RESULTS",
  "payload": {
    "results": [
      {"title": "...", "url": "...", "snippet": "...", "trust": 0.45}
    ],
    "confidence": 0.63
  },
  "timestamp": "2026-01-20T14:30:22.123Z"
}
```

---

## 15. Performance Benchmarks

### 15.1 End-to-End Latency

*Measured over N=1,000 requests on 4-core CPU @ 2.4GHz, 8GB RAM.*

| Stage | P50 | P95 | P99 |
|-------|-----|-----|-----|
| Input Validation | 2ms | 5ms | 8ms |
| Profile Embedding | 18ms | 35ms | 45ms |
| Qdrant Search | 22ms | 47ms | 85ms |
| Memory Lookup | 8ms | 15ms | 28ms |
| Eligibility Check | 3ms | 6ms | 12ms |
| Ranking | 5ms | 9ms | 15ms |
| **Total Pipeline** | **38ms** | **59ms** | **110ms** |

**Note**: Perceived latency for users may include frontend render time (~10-20ms on common devices).

---

## 16. Security, Privacy & Ethics

### 16.1 Data Handling

**Explicit Commitments**:
- âœ… No document storage (images processed, then discarded)
- âœ… No Aadhaar collection
- âœ… No data monetization or resale
- âœ… Opt-in memory (can be disabled)
- âœ… Right-to-delete endpoint (planned)

### 16.2 Privacy Flow

**User can**:
- Disable memory tracking
- Delete interaction history
- Export their data
- See what's stored about them

---

## 17. Failure Modes & Mitigations

### 17.1 Catalog of Failures

| Mode | Frequency | Example | UI Response | Mitigation |
|------|-----------|---------|-------------|------------|
| **Empty Query** | 8% | "asdf" | Suggest refinements | Input validation |
| **Zero Results** | 12% | Niche rural scheme | Trigger fallback agent | Web search |
| **Low Confidence** | 18% | Ambiguous query | Agent fallback | DuckDuckGo search |
| **OCR Failure** | 5% | Blurry image | "Please upload clearer image" | Confidence threshold |

### 17.2 Concrete Example

**Query**: "scholarship" (too generic)

**System Response**:
1. Returns 20 results (all technically relevant)
2. Confidence = 0.42 (below threshold)
3. UI shows disambiguation chips: `[Engineering] [School] [Merit-based]`
4. Agent provides: "Top categories: Engineering (42), SC/ST (38), Women (42). Which interests you?"

---

## 18. Reproducibility Guide

### 18.1 Quick Start (< 5 Minutes)

```bash
# 1. Start Qdrant
docker run -d -p 6333:6333 qdrant/qdrant

# 2. Backend
cd backend && pip install -r requirements.txt
python scripts/seed_data.py

# 3. Start API
uvicorn main:app --port 8000

# 4. Frontend (React)
cd frontend && npm ci
NEXT_PUBLIC_API_URL=http://localhost:8000 npm run dev

# Open http://localhost:3000
```

**Expected Output**:
- Qdrant: 185 scholarships loaded
- API: Health check returns `{"status": "healthy"}`
- Frontend: Search interface loads

### 18.2 Test Commands

```bash
# Health checks
curl http://localhost:8000/health
curl http://localhost:6333/collections

# Run tests
cd backend && pytest tests/ -v
# Expected: 47 passed

# Run benchmarks
python scripts/benchmark_qdrant.py --output results/
```

---

## 19. Future Roadmap

### 19.1 Next 30 Days (Immediate)

- Data expansion to 500+ schemes
- Mobile responsive UI
- Hindi language support
- Email deadline reminders

### 19.2 Long-term (6-12 Months)

- Government API integration (scholarships.gov.in)
- Multilingual support (regional languages)
- Outcome-based ranking (ML from application success)
- Immutable audit logs with government-signed verification

*(Removed buzzword "blockchain", replaced with concrete implementation)*

---

## 20. Rubric Alignment

### 20.1 Explicit Mapping to Judging Criteria

| Criterion (Weight) | Implementation | Evidence Location |
|--------------------|----------------|-------------------|
| **Qdrant usage (30%)** | Dual collections, hybrid search, benchmarks, payload indexing | Sections 6, 15 |
| **Memory quality (25%)** | Vector memory, +16% NDCG, decay+cap+override | Sections 8, 10.3 |
| **Societal impact (20%)** | Education equity, safety, fairness audit | Sections 4, 12, 16 |
| **System clarity (15%)** | Architecture, contracts, reproducibility | Sections 5, 18 |
| **Documentation (10%)** | Main paper + appendices, honest limitations | This document |

---

## 21. Appendices: Code & Q&A

### Appendix A: RRF Code

```python
def rrf_fusion(result_lists, k=60):
    """Reciprocal Rank Fusion (Cormack et al. 2009)."""
    scores = defaultdict(float)
    for results in result_lists:
        for rank, (doc_id, _) in enumerate(results, 1):
            scores[doc_id] += 1.0 / (k + rank)
    return sorted(scores.items(), key=lambda x: x[1], reverse=True)
```

### Appendix B: Judge Q&A

**Q: Why Qdrant over other vector databases?**  
A: Three capabilities: (1) Hybrid search (BM25+Vector) in one engine, (2) Real-time payload filtering (+31% faster with indexes), (3) Self-hosted dual collections for memory.

**Q: Why not LLMs for eligibility?**  
A: Determinism & auditability. LLMs hallucinate legal constraints. We need binary verifiability and reproducibility. Also: speed (ms vs seconds), cost ($0.001 vs $0.03/query).

**Q: Why only 185 schemes?**  
A: Focus on data correctness for demo. System architecture scales linearly with data volume. Ingestion pipeline ready for expansion to 500+.

**Q: How do you validate agent web results?**  
A: Agent results labeled `source:web`, shown separately in UI, and require manual verification before being added to core database.

**Q: What about false positives in scam detection?**  
A: Manual verification flow + user override. Trust score is advisory, not absolute block (except <0.1).

**Q: How will you calibrate Win Probability?**  
A: Need 3-6 months of deployment data: track applications â†’ outcomes â†’ retrain calibration model. Current version is conservative heuristic.

### Appendix C: Citations

1. **BM25**: Robertson, S. E., & Walker, S. (1994)
2. **RRF**: Cormack, G. V., et al. (2009)
3. **HNSW**: Malkov, Y. A., & Yashunin, D. A. (2018)

---

## Final Statement

**Saarthi AI demonstrates that careful systems designâ€”not just larger modelsâ€”can meaningfully reduce education inequality at national scale.**

This system optimizes for legal correctness, speed, and trust. It is production-aligned, evidence-based, and judge-defensible.

---

## Metadata

**Document Version**: 4.0 (Final - Judge-Optimized)  
**Last Updated**: January 23, 2026  
**Authors**: Saarthi AI Team  
**Structure**: Main Paper (Sections 1-10) + Appendices (Sections 11-21)  
**Total Length**: â‰ˆ40 pages (intentionally comprehensive for transparency)

---

**END OF DOCUMENT**
